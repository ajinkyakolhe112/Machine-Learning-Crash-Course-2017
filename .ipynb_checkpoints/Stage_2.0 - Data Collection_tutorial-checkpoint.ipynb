{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with HTML tags\n",
    "\n",
    "**Imp Tags**\n",
    "\n",
    "1. id\n",
    "    - unique id of the element. Might not be present in all documents\n",
    "2. a\n",
    "    - tag for url\n",
    "3. div span\n",
    "    - division of html into sections\n",
    "4. p\n",
    "    - paragraph tag\n",
    "5. h1 to h6\n",
    "    - header tags, h1 to h6\n",
    "6. ol ul & li\n",
    "    - Numbered list and Bulletpoints lists\n",
    "7. table td th tr\n",
    "    - Table in the doc\n",
    "8. img\n",
    "    - Image tag\n",
    "    \n",
    "## Tag vs Attribute\n",
    "```python\n",
    "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "<id=\"link2\">test</id>\n",
    "```\n",
    "\n",
    "These attributes id, title, class can be used on most html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating soup object\n",
    "# import necessary libraries\n",
    "import urllib.request  #Library used to query a website\n",
    "from bs4 import BeautifulSoup  #Library used to parse the data returned from the website\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page)\n",
    "\n",
    "\"\"\"\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#differences-between-parsers\n",
    "\n",
    "soup_slow = BeautifulSoup(page.content, 'html.parser') # Uses Regular expression so slow but powerful\n",
    "soup_fast = BeautifulSoup(page.content, 'lxml') # Uses tree structure so fast but expects proper format\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Functions\n",
    "1. find_all or findAll\n",
    "2. getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')\n",
    "\n",
    "\"\"\"\n",
    "soup.find_all also works but will be deprecated in future\n",
    "soup.findAll way to go in future\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('a', attrs ={\"class\":\"title\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"a\",attrs={\"id\":\"link3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"a\",id=\"link3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(id=\"link3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "soup.find_all(id=re.compile(\"link[0-2]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll(tagName) # possible html tags???\n",
    "soup.findAll(,attrs ={\"class\":\"name\"})\n",
    "soup.findAll(,{\"class\":\"name\"})\n",
    "soup.findAll({h1,h2,h3})\n",
    "soup.find(\"div\", {\"id\":\"bodyContent\"}).findAll(\"a\",href=re.compile(\"^(/wiki/)((?!:).)*$\"))\n",
    "images = soup.findAll(\"img\", {\"src\":re.compile(\"\\.\\.\\/img\\/gifts/img.*\\.jpg\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BeautifulSoup on World Wide Web\n",
    "\n",
    "Two ways to find details of the data you want to extract\n",
    "\n",
    "1. Use Ctr + U\n",
    "2. Use Right Click & Inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Web Scraping\n",
    "\n",
    "Find out the url format\n",
    "\n",
    "Right Click => Inspect => Network Tab => Url for loading next dynamic page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spoofing User agent\n",
    "\n",
    "Google Search \"What is my User Agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.40 Safari/537.36',}\n",
    "page = requests.get(\"https://www.google.com\",headers = header)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
